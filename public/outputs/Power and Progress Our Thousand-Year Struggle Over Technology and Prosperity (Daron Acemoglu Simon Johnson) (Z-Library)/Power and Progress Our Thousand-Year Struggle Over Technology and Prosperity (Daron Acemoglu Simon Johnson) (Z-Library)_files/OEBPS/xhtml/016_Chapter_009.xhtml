<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>

    <title>Power and Progress: Our Thousand-Year Struggle Over Technology and Prosperity</title>
    <meta content="urn:uuid:088af2eb-2978-493e-af7d-0a134c4155be" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link rel="stylesheet" type="text/css" href="../../stylesheet.css"/>
<link rel="stylesheet" type="text/css" href="../../page_styles.css"/>

  


<link href="../../calibreHtmlOutBasicCss.css" type="text/css" rel="stylesheet" />

</head>
<body>

<div class="calibreMeta">
  <div class="calibreMetaTitle">
  
  
    
    <h1>
      <a href="../../../Power and Progress Our Thousand-Year Struggle Over Technology and Prosperity (Daron Acemoglu Simon Johnson) (Z-Library).html">Power and Progress
</a>
    </h1>
    
    
  
  </div>
  <div class="calibreMetaAuthor">
    Daron Acemoglu;Simon Johnson;

  </div>
</div>

<div class="calibreMain">

  <div class="calibreEbookContent">
    
      <div class="calibreEbNavTop">
        
          <a href="015_Chapter_008.xhtml" class="calibreAPrev">previous page
</a>
        

        
          <a href="017_Chapter_010.xhtml" class="calibreANext">next page
</a>
        
      </div>
    

    
<div class="galley-rw">
<section epub:type="bodymatter chapter" id="sec-chapter16">
<p class="cn" id="ji_1310" lang="en-US"><a id="page-253"></a><a href="toc.xhtml#toc16" id="toc_16">8</a></p>
<p class="ct" id="ji_1311" lang="en-US"><a href="toc.xhtml#toc16">Digital Damage</a></p>
<p class="ep-first-rule-above" id="ji_1312" lang="en-US">The good news about computers is that they do what you tell them to do. The bad news about computers is that they do what you tell them to do.</p>
<p class="eps" id="ji_1313" lang="en-US">—attributed to <span class="eps-name-sc" lang="">Ted Nelson</span></p>
<p class="ep1" id="ji_1314" lang="en-US">One might say that the process by which progressive introduction of new computerized, automated, and robotized equipment can be expected to reduce the role of labor is similar to the process by which the introduction of tractors and other machinery first reduced and then completely eliminated horses and other draft animals in agriculture.</p>
<p class="eps_last-rule-below" id="ji_1315" lang="en-US">—Wassily Leontief, “<span class="charoverride1" lang="">Technological Advance, Economic Growth, and the Distribution of Income</span>,” <span class="eps-year" lang="">1983</span></p>
<p class="cotx" id="ji_1316" lang="en-US"><span class="_idgendropcap" lang="">T</span>he beginnings of the computer revolution can be found on the ninth floor of MIT’s Tech Square building. In 1959‒1960, a group of often-unkempt young men coded there in assembly language into the early hours of the morning. They were driven by a vision, sometimes referred to as the “hacker ethic,” which foreshadowed what came to energize Silicon Valley entrepreneurs.</p>
<p class="tx" id="ji_1317" lang="en-US">Key to this ethic was decentralization and freedom. Hackers felt great disdain for the major computer company of that <a id="page-254"></a>era, IBM (International Business Machines). In their view, IBM wanted to control and bureaucratize information, whereas they believed that access to computers should be completely free and unlimited. Anticipating a mantra that would later become much misused by tech entrepreneurs, hackers argued that “all information should be free.” Hackers mistrusted authority, so much so that there was an almost anarchist element to their thinking.</p>
<p class="tx" id="ji_1318" lang="en-US">What became the more famous branch of the hacker community, emerging in Northern California in the early 1970s, was similarly distrustful of large companies. One of its luminaries, Lee Felsenstein, was a political activist who viewed computers as a means of liberating people and liked to quote “Secrecy is the keystone of all tyranny” from the science-fiction novel <span class="ital" lang="">Revolt in 2100</span>. Felsenstein worked on hardware improvements to democratize computing and break the grip of IBM and other incumbents.</p>
<p class="tx" id="ji_1319" lang="en-US">Another Northern California hacker, Ted Nelson, published what can be considered as a handbook of hacking, “Computer Lib,” which starts with the motto “THE PUBLIC DOES NOT HAVE TO TAKE WHAT IS DISHED OUT” and continues:</p>
<p class="ext_a" id="ji_1320" lang="en-US"><span class="tx-char" lang="">THIS BOOK IS FOR PERSONAL FREEDOM.</span></p>
<p class="ext_a1" id="ji_1321" lang="en-US"><span class="tx-char" lang="">AND AGAINST RESTRICTION AND COERCION…</span></p>
<p class="ext_a1" id="ji_1322" lang="en-US"><span class="tx-char" lang="">A chant you can take to the streets:</span></p>
<p class="ext_a1" id="ji_1323" lang="en-US"><span class="tx-char" lang="">COMPUTER POWER TO THE PEOPLE!</span></p>
<p class="ext_a2" id="ji_1324" lang="en-US"><span class="tx-char" lang="">DOWN WITH CYBERCRUD!</span></p>
<p class="cotx" id="ji_1325" lang="en-US"><span class="ital" lang="">Cybercrud</span> here is Nelson’s term for the lies that powerful people tell about computers and information—about how their experts had to control them.</p>
<p class="tx" id="ji_1326" lang="en-US">The hackers were not misfits at the margins of the computer revolution. They were instrumental in many advances in both software and hardware. They symbolized the values and attitudes that many computer scientists and entrepreneurs held, even when they did not share the hackers’ work and sanitary habits.</p>
<p class="tx" id="ji_1327" lang="en-US"><a id="page-255"></a>The view that the future of computing and information lay with decentralization was not confined to the scruffy, male hackers of Tech Square at MIT and Berkeley. Another pioneer, Grace Hopper, was pushing for greater decentralization in computing at the Department of Defense in the 1970s. Hopper played an important role as a software innovator, devising early programming conventions that culminated in the new language COBOL. Hopper also viewed computing as a way of broadening access to information, and she influenced how computing was used in one of the largest organizations in the world, the US armed forces.</p>
<p class="tx" id="ji_1328" lang="en-US">With the most promising technology of the era in the hands of visionaries like this, an astute contemporary could have reasonably predicted that the next several decades would further bolster countervailing powers against big business, create new productive tools for workers, and lay the foundations of even stronger shared prosperity.</p>
<p class="tx" id="ji_1329" lang="en-US">In the event, something very different transpired, and digital technologies became the graveyard of shared prosperity. Wage growth slowed down, the labor share of national income declined sharply, and wage inequality surged starting around 1980. Although many factors, including globalization and the weakening of the labor movement, contributed to this transformation, the change in the direction of technology was most important. Digital technologies automated work and disadvantaged labor vis-à-vis capital and lower-skilled workers vis-à-vis those with college or postgraduate degrees.</p>
<p class="tx" id="ji_1330" lang="en-US">This redirection cannot be understood without recognizing the broader social changes taking place in the United States. Businesses became better organized against labor and government regulations, but even more importantly, a new vision maintaining that maximizing profits and shareholder values was for the common good became an organizing principle for much of society. This vision, and the massive enrichment it offered, pushed the tech community in a direction very different from the one envisaged by the early hackers. The new vision was of a “digital utopia,” based on the top-down design of software to automate and <a id="page-256"></a>control labor. The resulting path of technology not only manufactured inequality but also failed to deliver on its promise of spectacular productivity growth, as we will see.</p>
<p class="h1" id="ji_1331" lang="en-US">A Reversal</p>
<p class="cotx" id="ji_1332" lang="en-US">Any hopes that the decades after the initial phases of the computer revolution would bring more shared prosperity were dashed rather swiftly. Economic growth after the mid-1970s would look nothing like growth in the 1950s or 1960s. Some of the slowdown was a result of the oil crises of 1973 and then 1979, which triggered high levels of unemployment and inflation—stagflation—throughout the Western world. But the more fundamental transformation, in the structure of economic growth, was about to come.</p>
<p class="tx" id="ji_1333" lang="en-US">US median real wages (hourly compensation) grew at above 2.5 percent per year between 1949 and 1973. Then from 1980 onward, median wages all but stopped growing—increasing only 0.45 percent per year, even though the average productivity of workers continued to rise (with an annual average growth rate of over 1.5 percent from 1980 to the present).</p>
<p class="tx" id="ji_1334" lang="en-US">This growth slowdown was far from equally shared. Workers with postgraduate degrees still enjoyed rapid growth, but men with a high school diploma or less saw their wages fall by about 0.45 percent, on average, every year between 1980 and 2018.</p>
<p class="tx" id="ji_1335" lang="en-US">It was not just a widening gap between workers with postgraduate degrees and those with low levels of education. Every dimension of inequality skyrocketed from 1980 onward. For example, the share of the richest 1 percent of US households in national income rose from around 10 percent in 1980 to 19 percent in 2019.</p>
<p class="tx" id="ji_1336" lang="en-US">Wage and income inequality tells only part of the story. The United States used to pride itself for its “American dream,” which meant people from modest backgrounds rising in terms of income and children doing better than their parents. From the 1980s onward, this dream came under growing pressure. For children born in 1940, 90 percent of them earned more than their <a id="page-257"></a>parents did, in inflation-adjusted terms. But for children born in 1984, the percentage was only 50 percent. The US public is fully aware of the bleak prospects for most workers. A recent survey by the Pew Research Center found that 68 percent of Americans think that today’s children will be financially worse off than their parents’ generation.</p>
<p class="tx" id="ji_1337" lang="en-US">Other dimensions of economic progress were reversed, too. In 1940, Black men and women earned less than half what White Americans earned. By 1979, hourly wages for Black men rose to 86 percent of the level for White men. After that time, the gap widened, with Black men now earning only 72 percent as much as White men. There is a similar reversal for Black women.</p>
<p class="tx" id="ji_1338" lang="en-US">The distribution of income between capital and labor also changed significantly. Throughout most of the twentieth century, about 67‒70 percent of national income went to workers, and the rest went to capital (in the form of payments for machinery and profits). From the 1980s onward, things started getting much better for capital and much worse for workers. By 2019, labor’s share of national income had dropped to under 60 percent.</p>
<p class="tx" id="ji_1339" lang="en-US">These broad trends are not confined to the United States, although for various reasons they have been less pronounced in other countries. Already by 1980, the US was more unequal than most other industrialized economies and subsequently had one of the sharpest rises in inequality. Several others were not far behind.</p>
<p class="tx" id="ji_1340" lang="en-US">Labor’s share of national income has been on a protracted downward trend in most industrialized economies. In Germany, for example, it fell from close to 70 percent in the early 1980s to around 60 percent in 2015. At the same time, the income distribution became more skewed in favor of the very richest people. From 1980 to 2020, the share of the top 1 percent increased from about 10 percent to 13 percent in Germany, and from 7 percent to almost 13 percent in the UK. During the same period, inequality increased even in Nordic countries: the share of the top 1 percent rose from about 7 percent to 11 percent in Sweden and from 7 percent to 13 percent in Denmark.</p>
<p class="h1" id="ji_1341" lang="en-US"><a id="page-258"></a>What Happened?</p>
<p class="cotx" id="ji_1342" lang="en-US">At some level, what happened is clear. There were two pillars of shared prosperity in the postwar period: alongside automation, new opportunities were created for all kinds of workers, and robust rent sharing (meaning the splitting of productivity and profit gains between capital and labor) kept wages buoyant. After about 1970, both pillars collapsed, most spectacularly in the United States.</p>
<p class="tx" id="ji_1343" lang="en-US">Even at the best of times, the directions of technology and high wages are contested. Left to their own devices, many managers would try to reduce labor costs by limiting wage raises and also by prioritizing automation, which eliminates labor from some tasks and weakens the bargaining power of workers. These biases then influence the direction of innovation, pushing technology more toward automation. As we saw in <a href="015_Chapter_008.xhtml">Chapter 7</a>, these tendencies were partly contained by collective bargaining during the decades that followed World War II, and unions further encouraged companies to introduce more skilled tasks and systematic training together with new machinery.</p>
<p class="tx" id="ji_1344" lang="en-US">The emaciation of the labor movement over the last several decades has been a double whammy for shared prosperity. Wage growth slowed down partly because US labor unions became weaker and could not negotiate the same terms for their workers. Even more importantly, without strong unions, worker voice on the direction of technology disappeared.</p>
<p class="tx" id="ji_1345" lang="en-US">Two other changes amplified the decline of labor and inequality. First, without countervailing powers from the labor movement, corporations and their managers developed a very different vision. Cutting labor costs became a priority, and sharing productivity gains with workers came to be viewed as akin to a failure of management. In addition to taking a harder line in wage negotiations, corporations shifted production toward nonunionized plants in the United States and increasingly abroad. Many firms introduced incentive pay, which rewarded managers and high performers, but at the expense of lower-skill workers. Outsourcing became fashionable as another cost-cutting strategy. Many <a id="page-259"></a>low-skill functions, including cafeteria work, cleaning, and security, used to be performed by employees of large organizations such as General Motors or General Electric. These employees used to benefit from the overall wage increases that these companies’ workforces enjoyed. In the cost-cutting vision of the post-1980s, however, this practice was seen as a waste, so managers outsourced these functions to low-wage outside providers, severing another channel of wage growth for workers.</p>
<p class="tx" id="ji_1346" lang="en-US">Second, it was not only companies choosing more automation from a given menu of technologies. With the new direction of the digital industry, the menu itself shifted powerfully toward greater automation and away from worker-friendly technologies. With a whole slew of digital tools enabling new ways of substituting machines and algorithms for labor, and little countervailing powers to oppose this move, many corporations embraced automation enthusiastically and turned their back on creating new tasks and opportunities for workers, especially those without a college degree. Consequently, although productivity (output per worker) continued to increase in the US economy, worker marginal productivity (how much that an additional hour of labor boosts production) did not keep up.</p>
<p class="tx" id="ji_1347" lang="en-US">It bears repeating that shared prosperity was not destroyed by automation per se, but by an unbalanced technology portfolio prioritizing automation and ignoring the creation of new tasks for workers. Automation was also rapid in the decades following World War II but was counterbalanced by other technological changes that raised the demand for labor. Recent research finds that from 1980 onward, automation accelerated; more significantly, there were fewer new tasks and technologies that created opportunities for people. This change accounts for much of the deterioration of workers’ position in the economy. The labor share in manufacturing, where the acceleration of automation and the slowdown in the creation of new tasks has been most pronounced, declined from around 65 percent in the mid-1980s to about 46 percent in the late 2010s.</p>
<p class="tx" id="ji_1348" lang="en-US">Automation has also been a major booster of inequality because it concentrates on tasks typically performed by low- and <a id="page-260"></a>middle-skill workers in factories and offices. Almost all the demographic groups that experienced real wage declines since 1980 are those that once specialized in tasks that have since been automated. Estimates from recent research suggest that automation accounts for as much as three-quarters of the overall increase in inequality between different demographic groups in the United States.</p>
<p class="tx" id="ji_1349" lang="en-US">The automotive industry is indicative of these trends. US car companies were some of the most dynamic employers in the country in the first eight decades of the twentieth century, and as we saw in <a href="015_Chapter_008.xhtml">Chapter 7</a>, they were at the forefront of not just automation but also the introduction of new tasks and jobs for workers. Blue-collar work in the automotive industry was plentiful and well paid. Workers without college degrees and sometimes even without high school diplomas were hired and trained to operate new, sophisticated machinery, and they received quite attractive wages.</p>
<p class="tx" id="ji_1350" lang="en-US">The nature and availability of work in the automobile industry changed fundamentally in recent decades, however. Many of the production tasks in the body shop, such as painting, welding, and precision work, as well as a range of assembly jobs, have been automated using robots and specialized software. The wages of blue-collar workers in the industry have not increased much since 1980. Achieving the American dream through the automotive industry is much harder today than in the 1950s or 1960s.</p>
<p class="tx" id="ji_1351" lang="en-US">One can see the implications of this change in technology and organization of production in the hiring strategies of the industry. Since the 1980s, the US automotive giants stopped hiring and training low-education workers for complex production tasks and started accepting just higher-skilled applicants with formal qualifications, and only after a battery of aptitude and personality tests and interviews. This new human-resource strategy was enabled by the fact that there were many more applicants than available jobs and many of them had postsecondary education.</p>
<p class="tx" id="ji_1352" lang="en-US">The effects of automation technologies on the American dream are not confined to the automotive industry. Blue-collar jobs on other factory floors and clerical jobs in offices, which <a id="page-261"></a>used to provide opportunities for upward mobility to people from disadvantaged backgrounds, have been the main target of automation by robots and software throughout the US economy. In the 1970s, 52 percent of US workers were employed in these “middle-class” occupations. By 2018, this number had fallen to 33 percent. Workers who once occupied these jobs were often pushed toward lower-paying positions, such as construction work, cleaning, or food preparation, and witnessed their real earnings plummet. As these jobs disappeared throughout the economy, so did many of the opportunities for workers with less than a postgraduate degree.</p>
<p class="tx" id="ji_1353" lang="en-US">Although the abatement of rent sharing and the automation focus of new technologies have been the most important drivers of inequality and the decline of the labor share, other factors have also played a role. Offshoring has contributed to worsening conditions for labor: numerous jobs in car manufacturing and electronics have been shifted to lower-wage economies, such as China or Mexico. Even more important has been rising merchandise imports from China that have adversely affected many US manufacturing industries and the communities in which they were concentrated. The total number of jobs lost to Chinese competition between 1990 and 2007, just before the Great Recession, may be as high as three million. However, the effects of automation technologies and the eclipse of rent sharing on inequality have been even more extensive than the consequences of this “China shock.”</p>
<p class="tx" id="ji_1354" lang="en-US">Import competition from China impacted mostly low-value-added manufacturing sectors, such as textiles, apparel, and toys. Automation, on the other hand, has concentrated in higher-value-added and higher-wage manufacturing sectors, such as cars, electronics, metals, chemicals, and office work. It is the dwindling of this latter set of jobs that has played a more central role in the surge in inequality. As a result, although competition from China and other low-wage countries has reduced overall manufacturing employment and depressed wage growth, it has been the direction of technological change that has been the major driver of wage inequality.</p>
<p class="tx" id="ji_1355" lang="en-US"><a id="page-262"></a>These technology and trade trends have sometimes devastated local communities as well. Many areas in the industrial heartland of the United States, such as Flint and Lansing in Michigan, Defiance in Ohio, and Beaumont in Texas, used to specialize in heavy industry and offered employment opportunities to tens of thousands of blue-collar workers. After 1970, however, these places were pushed into decline as workers were displaced from their jobs by automation. Other metropolitan areas, such as Des Moines in Iowa and Raleigh-Durham and Hickory in North Carolina, that used to specialize in textiles, apparel, and furniture were equally adversely affected by competition from cheap Chinese imports. Whether from automation or import competition, job losses in manufacturing put downward pressure on worker incomes throughout the local economy and reduced demand for retail, wholesale, and other services, in some cases plunging an entire region into a deep, long-lasting recession.</p>
<p class="tx" id="ji_1356" lang="en-US">The fallout from these regional effects has gone beyond economics and gives us a microcosm of the problems that the US economy has been facing more broadly. As manufacturing jobs disappeared, social problems multiplied. Marriage rates fell, out-of-wedlock childbirth increased, and mental health problems rose in the worst-affected communities. More broadly, job losses and worsening economic opportunities, especially for Americans without a college degree, appear to have been a major driver of the rise in what economists Anne Case and Angus Deaton call “deaths of despair”—premature deaths caused by drugs, alcohol, and suicide. Partly as a result of these deaths, US life expectancy at birth has declined for several years in a row, which is unparalleled in the recent history of Western nations.</p>
<p class="tx" id="ji_1357" lang="en-US">In some popular discussions of rising inequality, globalization is pitted against technology as competing explanations. It is often implied that technology represents the inevitable forces leading to inequality, while there is some degree of choice about how much globalization and import competition from low-wage countries the United States (and other advanced economies) should have allowed.</p>
<p class="tx" id="ji_1358" lang="en-US"><a id="page-263"></a>This is a false dichotomy. Technology does not have a preordained direction, and nothing about it is inevitable. Technology has increased inequality largely because of the choices that companies and other powerful actors have made. Globalization is not separate from technology in any case. The huge boom in imports from countries thousands of miles away and the complex global supply chains involved in the offshoring of jobs to China or Mexico are enabled by advances in communication technologies. With better digital tools to track and coordinate activities in faraway facilities, companies reorganized production and sent offshore many of the assembly and production tasks they used to perform in-house. In the process, they also eliminated many middle-skill, blue-collar jobs, exacerbating inequality.</p>
<p class="tx" id="ji_1359" lang="en-US">In fact, globalization and automation have been synergistic, both driven by the same urge to cut labor costs and sideline workers. They have both been facilitated by the lack of countervailing powers in workplaces and in the political process since 1980.</p>
<p class="tx" id="ji_1360" lang="en-US">Automation, offshoring, and import competition from China have also impacted other advanced economies, but in more nuanced forms. Collective bargaining did not decline as much in most of Europe. In the Nordic countries, union coverage has remained high. Not coincidentally, even though their inequality levels also increased, they did not experience the declines in real wages that have been such a major part of US labor market trends. In Germany, as we will see, companies often shifted workers from blue-collar occupations into new tasks, charting a somewhat different, more labor-friendly direction of technology. In France, too, minimum wages and unions have limited the rise in inequality, albeit at the cost of greater joblessness.</p>
<p class="tx" id="ji_1361" lang="en-US">These caveats notwithstanding, technology trends have been broadly similar across most Western countries and have had analogous implications. Most tellingly, jobs in blue-collar and clerical occupations have declined in almost all industrialized economies. </p>
<p class="tx" id="ji_1362" lang="en-US">All of this then begs two obvious questions: How did businesses manage to become so powerful vis-à-vis labor and to cripple <a id="page-264"></a>rent sharing? And why did technology turn antilabor? The answer to the first question, as we will see below, is related to a series of institutional transformations in the United States and other Western nations. The answer to the second also builds on these institutional changes but crucially involves the emergence of a new utopian (but in reality, largely dystopian) digital vision, which pushed technologies and practices in an increasingly antilabor direction. In the next several sections we start with the institutional developments and return to how the idealistic hacker ethic of the 1960s and 1970s morphed into an agenda for automation and worker disempowerment.</p>
<p class="h1" id="ji_1363" lang="en-US">The Liberal Establishment and Its Discontents</p>
<p class="cotx" id="ji_1364" lang="en-US">We saw in <a href="015_Chapter_008.xhtml">Chapter 7</a> how a sort of balance between business and organized labor emerged in the United States after the 1930s. It was undergirded by robust wage growth across jobs ranging from the unskilled to the highly skilled, and by a broadly worker-friendly direction of technology. In consequence, the political and economic landscape of the United States looked very different by the 1970s than in the early decades of the twentieth century. Gone was the overwhelming political and economic clout of mega-businesses, such as the Carnegie Steel Company and John D. Rockefeller’s Standard Oil.</p>
<p class="tx" id="ji_1365" lang="en-US">Emblematic of these changes was the consumer protection activism led by Ralph Nader, whose book <span class="ital" lang="">Unsafe at Any Speed</span>, published in 1965, was a manifesto for keeping corporations accountable. In this instance, activism focused on automobile manufacturers, although Nader’s target was all misbehaviors by business, especially big business.</p>
<p class="tx" id="ji_1366" lang="en-US">Several iconic government regulations resulted from consumer activism. The National Traffic and Motor Vehicle Safety Act of 1966, which set the first safety standards for automobiles, was a direct response to the issues that Nader publicized. The Environmental Protection Agency was launched in 1970, with an explicit remit to prevent pollution and environmental damage by <a id="page-265"></a>businesses. The Occupational Safety and Health Administration (OSHA) came into existence in December of the same year to protect the health and well-being of workers. Although some of these problems were previously monitored by the Bureau of Labor Standards, OSHA gained much greater authority over businesses. The Consumer Product Safety Act, enacted in 1972, was even more far-reaching, giving an independent agency authority to set standards, recall products, and bring lawsuits against companies to protect consumers against the risk of injury or death.</p>
<p class="tx" id="ji_1367" lang="en-US">Title VII of the Civil Rights Act of 1964 had already banned employment discrimination on the basis of race, gender, color, religion, and national origin, but this act had little bite without an agency enforcing it. That changed with the launch of the Equal Employment Opportunity Act of 1972, tasked with going after individual employers for discrimination against Black Americans and other minorities.</p>
<p class="tx" id="ji_1368" lang="en-US">The Food and Drug Administration (FDA), which had been around since the beginning of the century, significantly increased its powers because of the Kefauver-Harris amendment of 1962 and the US Public Health Service reorganizations of 1966‒1973. The impetus for these changes came from a number of highly publicized scandals in Europe and the United States, convincing lawmakers that the agency needed to be more independent and approve only drugs that were safe and effective. The year 1974 also witnessed the beginning of the Department of Justice’s action to break up AT&amp;T, which had dominated the telephone sector in the US.</p>
<p class="tx" id="ji_1369" lang="en-US">These changes reflected a new, more muscular regulatory approach. Many were implemented under a Republican president, Richard Nixon. Nixon’s embrace of regulation was not a sharp break with the postwar Republican establishment. Dwight Eisenhower had already moved in the same direction, defining himself as a “modern Republican,” meaning that he was going to maintain most of what was left of the New Deal.</p>
<p class="tx" id="ji_1370" lang="en-US">It was not just regulation. The 1960s witnessed the success of the civil rights movement and greater mobilization among left-wing Americans supporting civil rights and further political <a id="page-266"></a>reforms. Lyndon Johnson initiated the Great Society program and the War on Poverty, adapting some key tenets of a European-style social safety net to the US context.</p>
<p class="tx" id="ji_1371" lang="en-US">Not everyone saw these changes as beneficial. Constraints on business conduct often benefited workers and consumers but were resented by business owners and executives. Segments of the business sector had been organizing against regulations and legislation strengthening labor unions since the beginning of the twentieth century. Their activity accelerated during the New Deal, when executives from some of the largest corporations, including DuPont, Eli Lilly, General Motors, General Mills, and Bristol-Myers, founded organizations such as the American Enterprise Association (which later became the American Enterprise Institute, or AEI) and the American Liberty League to formulate criticisms of and alternatives to New Deal policies.</p>
<p class="tx" id="ji_1372" lang="en-US">After the war, many businesspeople continued to be animated by a belief that the country was being lost to the “liberals.” In his 1965 book, <span class="ital" lang="">The Liberal Establishment: Who Runs America and How</span>, M. Stanton Evans wrote that “the chief point about the Liberal Establishment is that it is in control.”</p>
<p class="tx" id="ji_1373" lang="en-US">Early pro-business, right-wing organizations and think tanks received funding from executives and wealthy Americans philosophically opposed to the New Deal. As is often the case, philosophy was mixed with material interests. Tax-exempt philanthropic and charitable donations by large US corporations have tended to support causes aligned with their strategic interests (for example, energy companies philanthropically funding anti-climate-science think tanks).</p>
<p class="tx" id="ji_1374" lang="en-US">The pernicious role of money in US politics has been much discussed. But the story is more nuanced than what is sometimes presumed. Corruption at the federal level is not unknown, and political stances sometimes change because of campaign contributions from wealthy donors. Most of the time, however, politicians and their staff need to be persuaded that a particular approach to public policy serves either the public interest or their constituency. Copious amounts of money alone cannot achieve this unless an alternative vision of how the market economy should <a id="page-267"></a>be organized becomes accepted. During the 1950s and 1960s, elements of such a vision started to come together.</p>
<p class="h1" id="ji_1375" lang="en-US">What Is Good for General Motors</p>
<p class="cotx" id="ji_1376" lang="en-US">In 1953 President Dwight Eisenhower nominated Charles Wilson, then the president of General Motors, as secretary of defense. During his confirmation hearing, Wilson had to defend his controversial decision to hold on to substantial shares of GM, and he coined the aphorism “What was good for our country was good for General Motors, and vice versa.”</p>
<p class="tx" id="ji_1377" lang="en-US">Wilson was arguing that he could not imagine a situation in which he would have to do something good for the country that would not be good for GM. But people misconstrue him as claiming that what was good for GM was good for the country, for understandable reasons. By the 1980s, the view that what was good for business, or even large corporations, was good for the country had become commonplace. This was an about-face from the prevailing attitudes of the 1930s, and the idea was now taking hold that shifting the rules to favor companies and to boost profits was the best possible way to help everyone.</p>
<p class="tx" id="ji_1378" lang="en-US">This intellectual reversal was rooted in a lot of hard work by political entrepreneurs and organizations. An intellectual leader in this endeavor was the conservative magazine<span class="ital" lang=""> National Review</span>, founded by William F. Buckley Jr. in 1955. Buckley intended his publication to counter the trends from the Left because “in its maturity, literate America rejected conservatism in favor of radical social experimentation.” He continued: “Since ideas rule the world, the ideologues, having won over the intellectual class, simply walked in and started to run things.”</p>
<p class="tx" id="ji_1379" lang="en-US">The Business Roundtable, an influential business organization, agreed that “business has very serious problems with the intellectual community, the media and the youth.… The continuing hostility of these groups menaces all business.” The roundtable’s 1975 advertisement in <span class="ital" lang="">Reader’s Digest</span> read, “The way we earn our ‘daily bread’ in this country is under attack as never before” and identified the threat as arguments such as the “free <a id="page-268"></a>enterprise system makes us selfish and materialistic” and “free enterprise concentrates wealth and power in the hands of a few.” The Chamber of Commerce, representing in theory all US businesses, joined the Business Roundtable and also started pushing against government regulations.</p>
<p class="tx" id="ji_1380" lang="en-US">George H. W. Bush’s 1978 speech to top executives at a conference in Boston, while Bush was seeking the Republican presidential nomination, captured this mood: “Less than fifty years ago, Calvin Coolidge could say that the business of America is business. Today, the business of America seems to be the regulation of business.”</p>
<p class="tx" id="ji_1381" lang="en-US">Efforts by various think tanks and leaders notwithstanding, still missing was a coherent paradigm that what was good for business was good for everybody. The productivity bandwagon was a key part of this new vision, but with its logic extended even further. Organizational changes or laws that are good for business must also be good for society at large because, with a similar reasoning, they will increase demand for workers and translate into shared prosperity. Take it one step further, and you get “trickle-down economics,” a term identified today with President Ronald Reagan’s economic policies in the 1980s, including the idea of cutting taxes on the very rich: when the rich face lower taxes, they will invest more, increasing productivity and benefiting everybody in society.</p>
<p class="tx" id="ji_1382" lang="en-US">Applying this perspective to regulation leads to conclusions that are diametrically opposed to the ideas that energized Ralph Nader and other consumer activists. According to this free-market view, if the market economy is working well, regulation is at best unnecessary. If incumbent firms are marketing unsafe or low-quality products, consumers will be upset, and this creates an opportunity for other companies or new entrants to offer better alternatives, to which consumers will enthusiastically switch.</p>
<p class="tx" id="ji_1383" lang="en-US">The same competitive process that underlies the productivity bandwagon can then act as a force to discipline product quality as well. Seen through these lenses, regulation may even be counterproductive, harming consumers and workers. If the market process was already incentivizing businesses to offer safe and <a id="page-269"></a>high-quality products, additional regulations would only divert effort and reduce profitability, forcing businesses to increase prices or reduce labor demand.</p>
<p class="tx" id="ji_1384" lang="en-US">These ideas about the idealized market process have been part of economic theory ever since Adam Smith’s<span class="ital" lang=""> The Wealth of Nations</span> introduced the notion of the invisible hand—a metaphor for the notion that the market provides good outcomes for everyone, if there is enough competition. There has always been debate on this point, with the other side taken by people like John Maynard Keynes, who points out that markets do not function in an idealized way. For example, as we have seen, the productivity bandwagon collapses when there is not enough competition in the labor market. The same is true without sufficient competition in the product market. Nor can we count on the market process delivering high quality when consumers have a hard time distinguishing unsafe products from better ones.</p>
<p class="tx" id="ji_1385" lang="en-US">The pendulum has periodically swung between more market-friendly and market-skeptical perspectives in academia and in policy circles. The postwar decades were decidedly on the market-skeptical side, partly under the influence of Keynes’s ideas and the policies and regulations introduced during the New Deal era. But there were many pockets of diehard pro-market economists—for example, at the University of Chicago and Stanford University’s Hoover Institution.</p>
<p class="tx" id="ji_1386" lang="en-US">These ideas started coalescing into a more coherent whole in the 1970s. There were many contributing factors at play here. Some intellectuals, such as Friedrich Hayek, offered widely read critiques of the postwar policy consensus. Hayek developed his theories in interwar Vienna, where free-market notions were popular and the disaster of central planning in the nearby Soviet Union only too visible. Hayek left Austria in the early 1930s and landed at the London School of Economics, where he further developed many of his ideas. In 1950 he moved to the University of Chicago, where his influence grew.</p>
<p class="tx" id="ji_1387" lang="en-US">Particularly important was Hayek’s view that markets, as a decentralized system, were much better at using the dispersed information in society. In contrast, whenever central planning or <a id="page-270"></a>government regulation was used to allocate resources, there was a loss of information about what consumers truly wanted and about how productivity improvements could be implemented.</p>
<p class="tx" id="ji_1388" lang="en-US">To be sure, regulation is never an easy process, and the postwar era was filled with unintended consequences and inefficiencies created by regulators. For example, the airline industry was tightly regulated by the Civil Aeronautics Board during much of this time. The board set schedules, routes, and airline fares, and decided which new airlines could enter new markets. As civil aviation technology improved and demand for air travel grew, these regulations became more arcane and contributed to massive inefficiencies in the industry. The Airline Deregulation Act of 1978 allowed airlines themselves to set fares. This made it easier for new airlines to enter the market, increasing competition and driving down prices in ways that were generally welcomed by consumers.</p>
<p class="h1" id="ji_1389" lang="en-US">On the Side of Angels and Shareholders</p>
<p class="cotx" id="ji_1390" lang="en-US">The idea that unregulated markets work in the interest of the nation and the common good became the basis for a new approach to public policy. Missing from this emerging consensus was a clear set of recommendations for business leaders—how should they behave, and what would justify their actions? The answers came from two economists at the University of Chicago, George Stigler and Milton Friedman. Stigler’s and Friedman’s views about economics and politics overlapped with Hayek’s, but in some ways went further. Both Stigler and Friedman were more opposed to regulations than Hayek was.</p>
<p class="tx" id="ji_1391" lang="en-US">Friedman, who, like Hayek and Stigler, was awarded the Nobel Prize in economics, made important contributions to many areas, including macroeconomics, price theory, and monetary policy. Arguably, however, his most influential work did not appear in an academic journal but in a short piece published in September 1970 in the <span class="ital" lang="">New York Times Magazine</span>, immodestly titled “A Friedman Doctrine.” Friedman argued that the “social responsibility” of business was misconstrued. Business should care only <a id="page-271"></a>about making profits and generating high returns for their shareholders. Simply put, “The social responsibility of business is to increase its profits.”</p>
<p class="tx" id="ji_1392" lang="en-US">Friedman articulated an idea that was already in the air. The previous decades had witnessed stinging criticisms of government regulations and more voices in favor of the market mechanism. Nevertheless, the impact of the Friedman doctrine is hard to exaggerate. At one fell swoop, it crystallized a new vision in which big businesses that made money were heroes, not the villains that Ralph Nader and his allies painted them as. It also gave business executives a clear mandate: raise profits.</p>
<p class="tx" id="ji_1393" lang="en-US">The doctrine also received support from a different angle. Another economist, Michael Jensen, argued that managers of publicly listed corporations were not sufficiently committed to their shareholders and were instead pursuing projects that glorified themselves or built wasteful empires. Jensen maintained that these managers needed to be controlled more tightly, but because that was difficult, the more natural path was to have their compensation tied to the value they created for shareholders. This meant giving managers big bonuses and stock options in order to focus them on boosting the company’s stock price.</p>
<p class="tx" id="ji_1394" lang="en-US">The Friedman doctrine, along with the Jensen amendment, brought us the “shareholder value revolution”: corporations and managers should strive to maximize market value. Unregulated markets, combined with the productivity bandwagon, would then work for the common good.</p>
<p class="tx" id="ji_1395" lang="en-US">The Business Roundtable agreed and suggested that citizens should be educated in “economics” because greater economic knowledge would make them more favorable to business and supportive of policies such as lower taxes that would boost economic growth and benefit everybody. In 1980 it stated: “The Business Roundtable believes that future changes in tax policy should aim at improving the investment or supply side of the economy in order to increase the quality and scope of our productive capacity.”</p>
<p class="tx" id="ji_1396" lang="en-US">Two additional implications of this doctrine may have been even more important. First, it justified all sorts of efforts at <a id="page-272"></a>moneymaking, for boosting profits was in alignment with the common good. Some companies pushed this even further. The combination of the Friedman doctrine and the lavish stock options to top executives motivated several executives to venture into gray areas and then into the red. The journey of the energy giant Enron, a darling of the stock market, is emblematic. The Houston-based company was selected as “America’s Most Innovative Company” six years in a row by <span class="ital" lang="">Fortune </span>magazine. But in 2001 it was revealed that Enron’s financial success was in large part a result of systematic misreporting and fraud, which boosted the company’s stock market performance (and made hundreds of millions of dollars for its executives). Although Enron was the culprit that is most keenly remembered today, many other corporations and executives were involved in similar shenanigans, and several more scandals were revealed in the early 2000s.</p>
<p class="tx" id="ji_1397" lang="en-US">Second, the doctrine altered the balance between managers and workers. Sharing of productivity gains between companies and workers was a key pillar of broad-based prosperity after 1945. It was bolstered by labor’s collective bargaining power to make corporations pay high wages, by social norms of sharing the benefits of growth, and even by ideas of “welfare capitalism,” as we saw in <a href="015_Chapter_008.xhtml">Chapter 7</a>. The Friedman doctrine pushed in a different direction: good CEOs did not have to pay high wages. Their social responsibility was solely to the shareholders. Many high-profile CEOs, such as General Electric’s Jack Welch, heeded the advice and took a tough stance against wage raises.</p>
<p class="tx" id="ji_1398" lang="en-US">Nowhere can the impact of the Friedman doctrine be seen more clearly than in business schools. The 1970s were the beginning of the professionalization of managers, and the share of managers trained in business schools increased rapidly during this period. In 1980, about 25 percent of CEOs in publicly listed firms had a business degree. By 2020, this number exceeded 43 percent. Many faculty at business schools embraced the Friedman doctrine and shared this vision with aspiring managers.</p>
<p class="tx" id="ji_1399" lang="en-US">Recent research shows that managers who attended business schools started implementing the Friedman doctrine, especially <a id="page-273"></a>when it came to wage setting. They stopped wage growth in their firms, compared to similar companies run by managers who did not attend business schools. Managers in the United States and Denmark without an MBA share with their workers about 20 percent of any increase in value added. For managers inculcated in business schools, this number is zero. Somewhat disappointingly for business schools and for economists from the Friedman-Jensen school, there is no evidence that business school‒trained managers increase productivity, sales, exports, or investment. But they do increase shareholder value because they cut wages. They also pay themselves more handsomely than other managers.</p>
<p class="tx" id="ji_1400" lang="en-US">Resistance to the New Deal, accompanied by the antiregulation, antilabor philosophical stances of some business executives and the Friedman doctrine, was not enough, however. In the early 1970s, wholesale deregulation and dismantling the labor movement were fringe ideas, even if more businesses were becoming vocal about the burdens of growing regulations. That changed with the oil-price shock of 1973 and the stagflation that followed, which were interpreted as a failure of the existing system and signs that the US economy was not working anymore. A course correction was needed, and the Friedman doctrine and its bolstering of the power of businesses against regulations and organized labor came to be seen as the answer.</p>
<p class="tx" id="ji_1401" lang="en-US">Ideas that used to be advocated by think tanks outside of the mainstream started gaining adherents among lawmakers and businesses. Barry Goldwater, the Republican presidential candidate in the 1964 election, failed to get the support of the broader business community in part because his antiregulation ideas appeared extreme at that time. By 1979, Goldwater was boasting, “Now that almost every one of the principles I advocated in nineteen sixty-four have become the gospel of the whole spread of the spectrum of politics, there really isn’t a heck of a lot left.” Ronald Reagan reaffirmed this conclusion shortly after his election, when he told a crowd of conservative activists, “Had there not been a Barry Goldwater willing to make that lonely walk, we would not be talking of a celebration tonight.”</p>
<p class="h1" id="ji_1402" lang="en-US"><a id="page-274"></a>Big Is Beautiful</p>
<p class="cotx" id="ji_1403" lang="en-US">Even if one bought into the view that the market mechanism works seamlessly, regulations are mostly unnecessary, and the business of business should be maximizing shareholder value, there was still a tricky issue from the viewpoint of large corporations.</p>
<p class="tx" id="ji_1404" lang="en-US">Many businesses have considerable ability to set their price because they dominate parts of the market or have a loyal clientele. Think of the market power of Coca-Cola, for example, which controls 45 percent of the carbonated soft drinks market and can significantly shape the industry’s prices. Monopoly means that the market mechanism starts breaking down. Things are even worse when these corporations can block entry by new competitors or when they are able to acquire competing businesses, as the robber barons of late nineteenth-century America understood all too well.</p>
<p class="tx" id="ji_1405" lang="en-US">Adam Smith, the original proponent of the market-mechanism magic, was damning in his account of how even small groups of businessmen getting together could damage the common good. In a famous passage in <span class="ital" lang="">The</span><span class="ital" lang=""> Wealth of Nations</span>, he wrote, “People of the same trade seldom meet together, even for merriment and diversion, but the conversation ends in a conspiracy against the public, or in some contrivance to raise prices.” Building on Smith’s ideas, many free-market advocates have remained skeptical of large corporations, and some of them raise alarms when mergers and acquisitions increase the power of big players.</p>
<p class="tx" id="ji_1406" lang="en-US">Thwarting the workings of the market is not the only reason for being suspicious of big businesses. A well-known proposition in economics is the Arrow replacement effect, named after the Nobel Prize–winning economist Kenneth Arrow and later popularized by the business scholar Clayton Christensen as the “innovator’s dilemma.” It states that large corporations are timid innovators because they are afraid of eroding their own profits from existing offerings. If a new product will eat into the revenues a corporation enjoys from what it is already doing, why go there? In contrast, a new entrant could be very keen on doing something quite different because it cares only about those new profits. The <a id="page-275"></a>available evidence bears out this conjecture. Among innovative firms, younger and smaller ones invest almost twice as much in research as a fraction of their sales and subsequently tend to grow much faster than older and larger businesses.</p>
<p class="tx" id="ji_1407" lang="en-US">Even more important is the impact of large corporations on political and social power. US Supreme Court justice Louis Brandeis nailed this when he stated, “We may have democracy, or we may have wealth concentrated in the hands of a few, but we can’t have both.” He was opposed to large corporations not just because they increased market concentration and created conditions of monopoly, undercutting the market mechanism. He maintained that as they became very large, they exercised disproportionate political power, and the wealth they created for their owners further degraded the political process. Brandeis did not focus as much on social power—for example, whose ideas and vision we listen to—but his reasoning extends to that domain as well. When a few companies and their executives achieve higher status and greater power, it becomes harder to counter their vision.</p>
<p class="tx" id="ji_1408" lang="en-US">By the 1960s, however, several economists were already articulating ideas that were more skeptical of the utility of antitrust measures, aimed at limiting the power of big business. Particularly important in this was George Stigler, who saw antitrust action as part of the overall meddling of governments, just like regulations. Stigler’s ideas influenced legal scholars with some knowledge of economics, most notably Robert Bork.</p>
<p class="tx" id="ji_1409" lang="en-US">Bork’s influence and persona extended far beyond academia. He was Richard Nixon’s solicitor general and then became acting attorney general after his predecessor and his deputy resigned rather than accepting the pressure from the president to fire Archibald Cox, the independent prosecutor going after the Watergate scandal. Bork did not have the same qualms and relieved Cox of his duties as soon as he took up the post.</p>
<p class="tx" id="ji_1410" lang="en-US">Bork’s greater influence was through his scholarship, however. He took Stigler’s and related ideas and articulated a new approach to antitrust and regulation of monopoly. At the center was the idea that large corporations dominating their market were not necessarily a problem that required government intervention. <a id="page-276"></a>The key question was whether they harmed consumers by raising prices, and the onus was on government authorities to prove that they were doing so. Otherwise, these companies could be presumed to benefit consumers through greater efficiency, and public policy should stand aside. So big companies like Google and Amazon may look like and walk like monopolies, but according to this doctrine, no government action was needed until they could be proven to have increased prices.</p>
<p class="tx" id="ji_1411" lang="en-US">The Manne Economics Institute for Federal Judges, founded in 1976 with corporate funding, instructed scores of judges in economics during intensive training camps, but the economics they taught was a very specific version based on Friedman’s, Stigler’s, and Bork’s ideas. Judges who attended these training sessions became influenced by their teaching and began using more of the language of economics in their opinions. Strikingly, they also started issuing more conservative decisions and ruling consistently against regulatory agencies and antitrust action. The Federalist Society, founded in 1982 with similarly generous support from antiregulation executives, had a similar aim—grooming pro-business, antiregulation law students, judges, and Supreme Court justices. It has been phenomenally successful; six of the current Supreme Court justices are among its alumni.</p>
<p class="tx" id="ji_1412" lang="en-US">The consequences of the new approach to big business were sweeping. Today the United States has some of the largest and most dominant corporations ever: Google, Facebook, Apple, Amazon, and Microsoft are jointly worth about one-fifth of US GDP. The value of the largest five corporations at the beginning of the twentieth century—when the public and reformers were up in arms about the problem of monopoly—was not more than one-tenth of GDP. This is not just about the tech sector. From 1980 to today, concentration (market power of the largest firms) increased in more than three-quarters of US industries.</p>
<p class="tx" id="ji_1413" lang="en-US">The new antitrust approach has been critical in this. The Department of Justice has blocked only a handful of mergers and acquisitions over the last four decades. This hands-off approach allowed Facebook to buy WhatsApp and Instagram, Amazon to acquire Whole Foods, Time Warner and America Online to join <a id="page-277"></a>together, and Exxon to merge with Mobil, reversing part of the breakup of Standard Oil. In the meantime, Google and Microsoft have purchased scores of start-ups and small companies that could have turned into their rivals.</p>
<p class="tx" id="ji_1414" lang="en-US">The implications of the rapid growth of big businesses are wide-ranging. Many economists argue that they are now enjoying greater market power, which they are exercising both to thwart innovation from rivals and to enrich their top executives and shareholders. Gargantuan monopolies are often bad news for consumers because they distort prices and innovation. They also spell trouble for the productivity bandwagon because they reduce competition for workers. They powerfully multiply inequality at the top by enriching their already-wealthy shareholders. Large corporations have sometimes boosted the earnings of their employees by sharing their profits with them. But another part of the institutional changes of the last several decades meant that this was not likely to happen: the eclipse of worker power.</p>
<p class="h1" id="ji_1415" lang="en-US">A Lost Cause</p>
<p class="cotx" id="ji_1416" lang="en-US">The effects of the Friedman doctrine on wage setting may have been as important as its direct impact. If managers maximizing shareholder value were on the side of the angels, then anything standing on their path was a distraction or—worse—an impediment to the common good. Hence, the Friedman doctrine gave an additional impetus to managers to campaign against the labor movement.</p>
<p class="tx" id="ji_1417" lang="en-US">Despite American unions’ important role in the shared prosperity of the decades that followed World War II, their relationship with management was always strained. When unions win elections for representation in a plant, we see a striking increase in the likelihood that the plant will close. This is partly because of multiplant corporations shifting their production to nonunionized establishments. Executives delay unionization votes and adopt various tactics to convince workers to reject unions; if this fails, the jobs are moved elsewhere.</p>
<p class="tx" id="ji_1418" lang="en-US">The conflict inherent in this relationship has both idiosyncratic and institutional roots. Some unions developed close ties <a id="page-278"></a>with organized crime because of their presence in activities that were controlled by the Mafia. Leaders such as Jimmy Hoffa, president of the International Brotherhood of Teamsters, came to signify this dark side and likely contributed to the decline in public support for labor organizations. Hoffa served time in prison for bribery and various other crimes, and was probably murdered by the Mafia.</p>
<p class="tx" id="ji_1419" lang="en-US">More important than the flaws of the union leaders has been the way in which American unions were organized. We saw in <a href="015_Chapter_008.xhtml">Chapter 7</a> that collective agreements in Sweden and other Nordic countries were organized in the context of the corporatist model, which attempted to cultivate greater communication and cooperation between management and workers. They also set wages at the industry level. The German system combines industry-level wage bargaining together with work councils at the firm level, which represent the worker voice on corporate boards. In the United States, on the other hand, the 1947 Taft-Hartley Act weakened some of the pro-union provisions of the Wagner Act and legislated that collective bargaining had to take place at the business-unit level. It also banned secondary industrial action, such as boycotts in sympathy with strikers. Consequently, American unions organize and negotiate wages in their immediate workplaces, with no industry coordination. This arrangement breeds more conflictual relations between business and labor. When managers think that a hard line against unions can reduce wages and create a cost advantage relative to competitors, they are less likely to accept union demands.</p>
<p class="tx" id="ji_1420" lang="en-US">Starting around 1980, the balance of power shifted further away from the labor movement. Particularly important was Ronald Reagan’s tough stance against the Professional Air Traffic Controllers Organization in 1981. When the organization’s negotiations with the Federal Aviation Administration stalled, it called a strike, even though industrial action by government employees was illegal. President Reagan was swift in firing striking workers, calling them a “peril to national safety.” Where Reagan led, private businesses followed, and several large employers hired new <a id="page-279"></a>workers when confronted with industrial actions rather than giving in to union demands.</p>
<p class="tx" id="ji_1421" lang="en-US">Even before Reagan and the corporate pushback, the United States was past peak unionization. Nevertheless, in the early 1980s there were still about eighteen million union workers, and 20 percent of wage and salary workers belonged to unions. Since then, there has been a steady decline, partly because of the tougher antiunion stance of businesses and politicians, and partly because employment in the more heavily unionized manufacturing sector has dwindled. In 2021 only 10 percent of workers were union members. Additionally, by the 1980s, most of the cost-of-living escalator clauses that ensured automatic wage increases without full-scale agreements had been negotiated out of union contracts, further weakening the hands of labor and the prospect for sharing of productivity gains with workers.</p>
<p class="tx" id="ji_1422" lang="en-US">This antilabor shift is not unique to the United States. Margaret Thatcher, who was elected British prime minister in 1979, prioritized deregulation, enacted myriad pro-business laws, and vigorously fought unions, so British unions have also lost much of their earlier strength.</p>
<p class="h1" id="ji_1423" lang="en-US">A Grim Reengineering</p>
<p class="cotx" id="ji_1424" lang="en-US">Rising industrial concentration and the waning of rent sharing were a first salvo against the shared prosperity model of the 1950s and 1960s, but by themselves would not have created the tremendous turnaround we witnessed. For that, the direction of technology would also have to move in an antilabor direction. This is where digital technologies enter the story, in a big way.</p>
<p class="tx" id="ji_1425" lang="en-US">The Friedman doctrine encouraged corporations to increase profits by whatever means necessary, and by the 1980s, this idea was embraced by the corporate sector. Executive compensation, in the form of stock options, strongly supported this shift. The culture at the top of corporations began to change. In the 1980s a big story for corporate America was rivalry from efficient Japanese manufacturers, first in consumer electronics and then in the <a id="page-280"></a>auto industry. The people who ran US firms felt a pressing need to respond.</p>
<p class="tx" id="ji_1426" lang="en-US">As a result of the broadly balanced investments in automation and new tasks in the 1950s and 1960s, worker marginal productivity had increased, and the labor share of income in manufacturing remained broadly constant, hovering close to 70 percent between 1950 and the early 1980s. But by the 1980s, many American managers came to see labor as a cost, not as a resource, and to withstand foreign competition, these costs needed to be cut. This meant reducing the amount of labor used in production through automation. Recall that automation increases output per worker but, by sidelining labor, it limits and may even reduce worker marginal productivity. When this happens on a large enough scale, there is less demand for workers and lower wage growth.</p>
<p class="tx" id="ji_1427" lang="en-US">To cut labor costs, US businesses needed a new vision and new technologies, which came, respectively, from business schools and the nascent tech sector. The main ideas on cost cutting are well summarized in a 1993 book by Michael Hammer and James Champy, <span class="ital" lang="">Reengineering the Corporation: A Manifesto for Business Revolution</span>. The book argues that US corporations had become highly inefficient, especially because there were too many middle managers and white-collar workers. The US corporation should therefore be reengineered to compete more vigorously, and new software could provide the tools.</p>
<p class="tx" id="ji_1428" lang="en-US">To be fair, Hammer and Champy emphasized that reengineering was not just automation, but they also took the view that more effective use of software would eliminate many unskilled tasks: “Much of the old, routine work is eliminated or automated. If the old model was simple tasks for simple people, the new one is complex jobs for smart people, which raises the bar for entry into the workforce. Few simple, routine, unskilled jobs are to be found in a reengineered environment.” In practice, the smart people for the complex jobs were almost always workers with college or postgraduate degrees. Well-paying jobs for noncollege workers became scant in reengineered environments.</p>
<p class="tx" id="ji_1429" lang="en-US">The high priests of the emerging vision came from the newly burgeoning management-consulting field. Management <a id="page-281"></a>consulting barely existed in the 1950s, and its growth coincides with efforts to remake corporations through “better” use of digital technology. Together with business schools, leading management-consulting companies such as McKinsey and Arthur Andersen also pushed cost cutting. As these ideas were increasingly preached by articulate management experts, it became harder for workers to resist.</p>
<p class="tx" id="ji_1430" lang="en-US">Just like the Friedman doctrine, <span class="ital" lang="">Reengineering the Corporation</span> crystallized ideas and practices that were already being implemented. By the time the book came out, several large US corporations had used software tools to downsize their workforces or expand operations without having to hire new employees. By 1971, IBM was prominently advertising its “word-processing machines” as a tool for managers to increase their productivity and automate various office jobs.</p>
<p class="tx" id="ji_1431" lang="en-US">In 1981 IBM launched its standardized personal computer, with a range of additional capabilities, and soon new software programs for automation of clerical work, including administrative and back-office functions, were being developed. As far back as 1980, Michael Hammer anticipated more extensive “office automation”:</p>
<p class="ext" id="ji_1432" lang="en-US">Office automation is simply an extension of the kinds of things that data processing has been doing for years, updated to take advantage of new hardware and software possibilities. Distributed processing to replace mail, source data capture to reduce retyping, and end-user oriented systems are the ways in which “office automation” will be brought beyond the traditional applications and to the aid of all segments of the office.</p>
<p class="tx" id="ji_1433" lang="en-US">A vice president of Xerox Company around the same time was predicting, “We may, in fact, witness the full blossoming of the postindustrial revolution when routine intellectual work becomes as automated as heavy mechanical work did during the 19th century.” Other commentators were more worried about these developments but still expected “the automation of all phases of information manipulation from gathering to dissemination.”</p>
<p class="tx" id="ji_1434" lang="en-US"><a id="page-282"></a>Interviews from the 1980s with workers both on shop floors and in offices indicated their anxiety in the face of new digital technologies. As one worker put it, “We don’t know what will be happening to us in the future. Modern technology is taking over. What will be our place?”</p>
<p class="tx" id="ji_1435" lang="en-US">It was the arrival of these early digital technologies that made Wassily Leontief, another Nobel Prize–winning economist, worry in 1983 that human labor would go the way of the horses and become mostly unnecessary for modern production.</p>
<p class="tx" id="ji_1436" lang="en-US">These expectations were not completely off the mark. A case study of the introduction of new computer software in a large bank finds that the new technologies adapted in the 1980s and early 1990s led to a significant reduction in the number of workers employed in check processing. Back-office tasks were automated equally rapidly across various industries during the same time.</p>
<p class="tx" id="ji_1437" lang="en-US">As these technologies spread, many relatively high-wage occupations started declining. In 1970 about 33 percent of American women were in clerical jobs, which paid decent salaries. Over the next six decades, this number declined steadily and is now down to 19 percent. Recent research documents that these automation trends have been a powerful contributor to the wage stagnation and declines for low- and middle-skill office workers.</p>
<p class="tx" id="ji_1438" lang="en-US">But where did the software to support downsizing come from? Not from the early hackers, who were steadfastly opposed to corporate control over computers. Designing software to fire workers would have been anathema to them. Lee Felsenstein anticipated this type of demand and railed against it: “The industrial approach is grim and doesn’t work: the design motto is ‘Design by Geniuses for Use by Idiots,’ and the watchword for dealing with the untrained and unwashed public is KEEP THEIR HANDS OFF!” Instead, he insisted on the importance of “the user’s ability to learn about and gain some control over the tool.” In the words of one of his associates, Bob Marsh, “We wanted to make the microcomputer accessible to human beings.”</p>
<p class="tx" id="ji_1439" lang="en-US">William (Bill) Henry Gates III had a different idea. Gates enrolled at Harvard to study pre-law and then mathematics, but <a id="page-283"></a>left school in 1975 to found Microsoft with Paul Allen. Allen and Gates built on the pathbreaking work of many other hackers to produce a rudimentary compiler, using BASIC, for the Altair, which they then turned into an operating system for IBM. Gates had his eye on monetization from the beginning. In a 1976 open letter, he accused hackers of stealing software programmed by Allen and himself: “As the majority of hobbyists must be aware, most of you steal your software.”</p>
<p class="tx" id="ji_1440" lang="en-US">Gates was determined to find a way of making a lot of money from software. Selling to large, established companies was the obvious way forward. Where Microsoft and Bill Gates led, much of the rest of the industry followed. By the early 1990s, a major part of the computer industry, including emerging household names such as Lotus, SAP, and Oracle, supplied office software to big corporations and were spearheading the next phase of office automation.</p>
<p class="tx" id="ji_1441" lang="en-US">Although automation based on office software was likely more important for employment, the overall trends can also be seen in the effects of another iconic technology of the era: industrial robots.</p>
<p class="tx" id="ji_1442" lang="en-US">Robots are the quintessential automation tool, targeting the performance of repetitive manual tasks, including the moving of objects, assembly, painting, and welding. Autonomous machines performing human-like tasks have captured popular imaginations since Greek mythology. The idea came into clearer focus with <span class="ital" lang="">R.U.R.</span>, an imaginative 1920 play by the Czech writer Karel Čapek that introduced the word <span class="ital" lang="">robot</span>. In this science-fiction tale, robots run factories and work for humans, but it does not take them long to turn against their masters. Fears of robots doing all sorts of bad things have been part of the public conversation ever since. Science fiction aside, one thing is for certain: robots do automate work.</p>
<p class="tx" id="ji_1443" lang="en-US">The United States was a laggard in robotics in the 1980s, in part because it was not under the same demographic pressures that affected countries such as Germany and Japan. In the 1990s, robots started spreading rapidly in US manufacturing. Just like <a id="page-284"></a>automation software in offices, robots did what their designers intended them to do—they reduced the labor intensity of production. For example, the automotive industry was completely revolutionized by robots and, as a result, now employs many fewer workers in traditional blue-collar tasks.</p>
<p class="tx" id="ji_1444" lang="en-US">Robots increase productivity. However, in US manufacturing, rather than launching the productivity bandwagon, they have reduced employment and wages. As with the automation of white-collar jobs with office software, the elimination of blue-collar jobs by robotics technology was swift. Some of the best jobs available to workers without a college degree in the 1950s and 1960s were in welding, painting, material handling, and assembly, and these jobs have steadily disappeared. In 1960 almost 50 percent of American men were in blue-collar occupations. This number has subsequently fallen to about 33 percent.</p>
<p class="h1" id="ji_1445" lang="en-US">Once Again, a Matter of Choice</p>
<p class="cotx" id="ji_1446" lang="en-US">Could the turn toward automation, starting around 1980, be the inevitable result of technology’s progress? Perhaps advances in computers were by their nature more amenable to automation. Although it is difficult to dismiss this possibility entirely, there is plenty of evidence that the direction of technology and the emphasis on cost cutting were choices.</p>
<p class="tx" id="ji_1447" lang="en-US">Digital technologies, even more so than electricity, discussed in <a href="015_Chapter_008.xhtml">Chapter 7</a>, are general purpose, enabling a wide range of applications. Different choices on their direction will likely translate into gains and losses for different segments of the population. In fact, many of the early hackers thought that computers could empower workers and enrich their work rather than automate it. We will see in <a href="017_Chapter_010.xhtml">Chapter 9</a> that they were not wrong: several important digital tools powerfully complemented human labor. Unfortunately, however, most efforts in the blossoming computer industry went toward automation.</p>
<p class="tx" id="ji_1448" lang="en-US">Moreover, although they had access to the same software tools and robotics technology, other countries made very different choices <a id="page-285"></a>than their American counterparts. For example, German manufacturing firms still had to negotiate with unions and explain their decisions to worker representatives on their corporate boards. They were also understandably wary of laying off workers who had gone through years of apprenticeship in the company and developed a range of relevant skills. They thus made technological and organizational adjustments to increase the marginal productivity of the workers they had already trained, blunting automation’s impact.</p>
<p class="tx" id="ji_1449" lang="en-US">Consequently, even though industrial automation has been faster in Germany, with the number of robots per industrial workers more than twice that in the United States, companies made efforts to retrain blue-collar workers and reallocate them to new tasks, often in technical, supervisory, or white-collar occupations. This creative use of worker talent is also visible in how German companies use new software in manufacturing. At the center of programs such as Industry 4.0 or Digital Factory, which became popular in German manufacturing in the 1990s and 2000s, was the use of computer-assisted design and computer-aided quality control that enabled well-trained workers to contribute to design and inspection—for instance, by working on virtual prototypes or by using software tools to detect problems. These efforts ensured that worker marginal productivity increased, even as the German industry rapidly introduced new robots and software tools. Tellingly, following robot adoption, the reallocation of blue-collar workers to new, technical tasks is more pronounced in German workplaces, where labor unions are stronger.</p>
<p class="tx" id="ji_1450" lang="en-US">Germany started the postwar era with labor shortages because of the significant fraction of its male population that had perished in the war. Labor scarcity continued as birthrates declined in Germany faster than in the rest of Europe, creating an acute need for working-age people in the country by the 1980s. In the same way that a shortage of skilled labor encouraged more worker-friendly uses of technology in the nineteenth-century United States, it induced German firms to find ways of making best use of their employees’ capabilities by investing in skills during apprenticeship programs that now run three or four years. <a id="page-286"></a>It also encouraged the retraining of workers for more technical tasks as automation technologies were adopted.</p>
<p class="tx" id="ji_1451" lang="en-US">As a result of these priorities and adjustments, the number of workers in the auto industry in Germany rose between 2000 and 2018. These gains have been accompanied by an increase in the fraction of white-collar and technical occupations, such as engineering, design, and repair, in the industry from 30 percent to 40 percent. In the meantime, US automakers, whose output followed a similar trajectory to their German counterparts, reduced employment by about 25 percent and did not undertake similar occupational upgrading.</p>
<p class="tx" id="ji_1452" lang="en-US">This was not just a German story. Japanese firms, also facing a declining labor force, have been even faster in adopting robots. But they too combined automation with the creation of new tasks. With the emphasis on flexible production and quality, Japanese companies did not automate all of the jobs on the factory floor, instead creating a range of complex and well-paid tasks for their employees. They also invested as much in software for flexible planning, supply-chain management, and design tasks as software tools used for automation. Overall, during the same time period, Japanese automakers did not reduce their workforces in the same way that their American peers did.</p>
<p class="tx" id="ji_1453" lang="en-US">In Finland, Norway, and Sweden, where collective bargaining remained important and a large share of the industrial workforce is still covered by collective agreements, corporations have continued to share productivity gains with workers, and automation has often been combined with other technological adaptations more favorable to labor.</p>
<p class="tx" id="ji_1454" lang="en-US">In the 1950s and 1960s, US labor unions could also object to excessive automation technologies or demand other changes to protect workers, as in Germany. But by the 1990s, the US labor movement was enfeebled. With the prevailing vision emphasizing cost cutting and the superiority of fully automated processes, American labor came to be seen as something to be eliminated from the production process, rather than as people with skills who could become more valuable with training and appropriate technological investments. These automation and labor-cutting <a id="page-287"></a>choices then became self-reinforcing, for automation also reduced the number of unionized blue-collar workers, delivering another blow to the labor movement.</p>
<p class="tx" id="ji_1455" lang="en-US">Government policy also contributed to these developments. The US tax system has always favored capital relative to labor, imposing lower effective taxes on capital earnings than labor income. Starting in the 1990s, the asymmetry of capital taxation and labor-income taxation intensified, especially for equipment and software capital. Successive administrations reduced corporate income and federal income taxes on the richest Americans, pushing down the tax rate on capital (because returns on capital investments in corporate profits go disproportionately to those people). Starting in 2000, capital tax cuts went into overdrive with increasingly generous depreciation allowances on equipment and software capital. Although these were at first supposed to be temporary, they were often extended and then made more generous.</p>
<p class="tx" id="ji_1456" lang="en-US">Overall, whereas the average tax rate on labor income, based on payroll and federal income taxes, remained over 25 percent for the last thirty years, the effective tax rates on equipment and software capital (including all capital gains and income taxes) fell from around 15 percent to less than 5 percent in 2018. These tax incentives meant that businesses had even a greater appetite for automation equipment, and their demand fueled further development of automation technologies in a self-reinforcing cycle.</p>
<p class="tx" id="ji_1457" lang="en-US">The evolution of federal research and science policy may have been another contributing factor. Starting from before World War II, government funding of science and private-sector research was generous, especially in areas that were national defense priorities. This was a powerful inducement to new critical areas, such as antibiotics, semiconductors, satellites, aerospace, sensors, and the internet.</p>
<p class="tx" id="ji_1458" lang="en-US">Over the last five decades, both government strategic technology leadership and funding declined. Federal spending on research and development fell from around 2 percent of GDP in the mid-1960s to about 0.6 percent today. The government also became more likely to support the research priorities set by leading corporations. This new landscape then allowed large corporations, <a id="page-288"></a>especially in the digital area, to determine the direction of technology. Their incentives and mind-set pushed toward more and more automation.</p>
<p class="tx" id="ji_1459" lang="en-US">US technologies and business strategies spread more broadly, even if countries differed in how they adopted and configured automation technologies, as we have seen. The Friedman doctrine and ideas related to the use of digital tools in order to cut costs influenced business practices in the United Kingdom and the rest of Europe. For example, the effects of managers trained in business schools are remarkably similar in Denmark and the United States. Management consulting expanded throughout the Western world, and new digital technologies and robots were adopted rapidly. Automation and globalization reduced the fraction of the labor force working in blue-collar and clerical occupations in essentially all industrialized nations. Thus, despite variation across countries, the direction of progress in the US has had a significant global impact.</p>
<p class="h1" id="ji_1460" lang="en-US">Digital Utopia</p>
<p class="cotx" id="ji_1461" lang="en-US">The direction of technology that prioritized automation cannot be understood unless we recognize the new digital vision that emerged in the 1980s. This vision combined the drive to cut labor costs, rooted in the Friedman doctrine, with elements of the hacker ethic, but abandoned the philosophy of early hackers such as Lee Felsenstein that was antielitist and suspicious of corporate power. Felsenstein admonished IBM and other big corporations because they were trying to misuse technology with their ideology of “design by geniuses for use by idiots.” The new vision instead embraced the top-down design of digital technologies aimed at eliminating people from the production process.</p>
<p class="tx" id="ji_1462" lang="en-US">There was a euphoria, reminiscent of the way that Ferdinand de Lesseps used to talk about building the Suez and Panama Canals, about what technology could achieve, provided that it was shepherded by talented programmers and engineers. Bill Gates summed up this techno-optimism when he proclaimed, <a id="page-289"></a>“Show me a problem, and I’ll look for technology to fix it.” That technology may be socially biased—in their favor and against most people—does not seem to have occurred to Gates and his confederates.</p>
<p class="tx" id="ji_1463" lang="en-US">The transformation from the hacker ethic to corporate digital utopia was largely about following the money and social power. By the 1980s, software engineers could either have their ideals or gain tremendous riches by signing up with companies that were becoming larger and more powerful. Many chose the latter.</p>
<p class="tx" id="ji_1464" lang="en-US">Meanwhile, antiauthoritarianism morphed into a fascination with “disruption,” meaning that disrupting existing practices and livelihoods was welcome or even encouraged. The precise words differed, but the underlying thinking was reminiscent of British entrepreneurs in the early 1800s, who felt fully justified in ignoring any collateral damage they created along their path, especially on workers. Later, Mark Zuckerberg would make “Move fast and break things” a mantra for Facebook.</p>
<p class="tx" id="ji_1465" lang="en-US">An elitist approach came to dominate almost the entire industry. Software and programming were things in which very talented people excelled, and the less able were of limited use. Journalist Gregory Ferenstein interviewed dozens of tech start-up founders and leaders who expressed these opinions. One founder stated that “very few are contributing enormous amounts to the greater good, be it by starting important companies or leading important causes.” It was also generally accepted that those few seen as contributing to the public good by launching new businesses should be handsomely rewarded. As the Silicon Valley entrepreneur Paul Graham, one of<span class="ital" lang=""> Businessweek</span>’s “twenty-five most influential people on the web,” put it, “I’ve become an expert on how to increase economic inequality, and I’ve spent the past decade working hard to do it.… You can’t prevent great variations in wealth without preventing people from getting rich, and you can’t do that without preventing them from starting startups.”</p>
<p class="tx" id="ji_1466" lang="en-US">Even more consequential was the elitism of this vision when it came to the nature of work. Most people were not smart enough to even excel at the jobs that were assigned to them, so the use of <a id="page-290"></a>software designed by technology leaders to reduce corporations’ dependence on these fallible people was fully justified. Hence, automating work became an integral part of this vision, and perhaps its most powerful implication.</p>
<p class="h1" id="ji_1467" lang="en-US">Not in the Productivity Statistics</p>
<p class="cotx" id="ji_1468" lang="en-US">The productivity bandwagon is foundational to this vision of a digital utopia. If many workers are made worse off by technological improvements, it becomes much harder to claim that productivity gains are in the common good.</p>
<p class="tx" id="ji_1469" lang="en-US">The bandwagon is less likely to operate when employers have too much power relative to workers, when technology is moving in an antilabor direction, and when productivity gains do not translate into employment growth in other sectors. But there is an even more fundamental problem. During the last several decades, there has been less productivity growth to share, even though we are bombarded with new products and apps every day.</p>
<p class="tx" id="ji_1470" lang="en-US">Generations that lived in the 1960s and 1970s used the same (rotary dial) telephone and the same TV set for decades, until they broke down and buying new equipment became inevitable. Today, most middle-class families upgrade their mobile phones, TVs, or other electronics every year or two: new models are faster, glossier, and more capable because of their myriad new features. For example, Apple releases a new iPhone almost every year.</p>
<p class="tx" id="ji_1471" lang="en-US">Indeed, the rate of overall innovation appears to have skyrocketed. In 1980, there were 62,000 domestic patents filed with the United States Patent and Trademark Office. By 2018, this number had increased to 285,000, a nearly fivefold rise. Over the same period, the population of the United States rose by less than 50 percent.</p>
<p class="tx" id="ji_1472" lang="en-US">Moreover, much of the growth in both patenting and research spending is driven by new patents in electronics, communication, and software, the fields that were supposed to propel us forward. But look a little closer, and the fruits of the digital revolution are much harder to see. In 1987, Nobel Prize winner Robert Solow <a id="page-291"></a>wrote: “You can see the computer age everywhere but in the productivity statistics,” pointing out the small gains from investments in digital technologies.</p>
<p class="tx" id="ji_1473" lang="en-US">Those more optimistic about computers told Solow that he had to be patient; productivity growth would soon be upon us. More than thirty-five years have passed, and we are still waiting. In fact, the US and most other Western economies have had some of the most unimpressive decades in terms of productivity growth since the beginning of the Industrial Revolution.</p>
<p class="tx" id="ji_1474" lang="en-US">Focusing on the same measure of productivity we discussed in <a href="015_Chapter_008.xhtml">Chapter 7</a>, total factor productivity (TFP), US average growth since 1980 has been less than 0.7 percent, compared to TFP growth of approximately 2.2 percent between the 1940s and 1970s. This is a remarkable difference: it means that if TFP growth had remained as high as it had been in the 1950s and 1960s, every year since 1980 the US economy would have had a 1.5 percent higher GDP growth rate. The productivity slowdown is not just a problem of the era following the global financial crisis of 2008. US productivity growth between the booming years of 2000 and 2007 was less than 1 percent.</p>
<p class="tx" id="ji_1475" lang="en-US">This evidence notwithstanding, technology leaders maintain that we are lucky to be alive in this age of technology and innovation. The journalist Neil Irwin summarizes this optimistic view succinctly in the <span class="ital" lang="">New York Times</span>: “We’re in the golden age of innovation, an era in which digital technology is transforming the underpinnings of human existence.”</p>
<p class="tx" id="ji_1476" lang="en-US">Slow productivity growth is then simply a problem of not fully recognizing all the benefits we are getting from new innovations. For example, Google’s chief economist, Hal Varian, argues that slow productivity growth is rooted in mismeasurement: we are not accurately incorporating consumer benefits from products such as smartphones that simultaneously act like cameras, computers, global positioning devices, and music players. Nor are we appreciating the true productivity gains from better search engines and abundant information on the web. The chief economist of Goldman Sachs, Jan Hatzius, agrees: “We think it is more <a id="page-292"></a>likely that the statisticians are having a harder and harder time accurately measuring productivity growth, especially in the technology sector.” He reckons that the true productivity growth of the US economy since 2000 could be several times greater than statistical agencies’ estimates.</p>
<p class="tx" id="ji_1477" lang="en-US">In principle, consumer and productivity benefits from new technologies should be in the TFP numbers we reported, which are based on GDP growth adjusted for changes in prices, quality, and product variety. Thus, products that significantly increase consumer welfare should translate into much higher TFP growth. In practice, of course, such adjustments are imperfect, and mismeasurement can arise. Nevertheless, these problems are unlikely to explain away the productivity slowdown.</p>
<p class="tx" id="ji_1478" lang="en-US">The same problem of undercounting quality improvements and broader social benefits from new products has been around ever since national income statistics were first devised. It is far from clear that digital technologies have worsened this problem. Indoor plumbing, antibiotics, and the highway system generated a panoply of new services and indirect effects that were only imperfectly measured in national statistics. Moreover, measurement problems cannot account for the current productivity slowdown; industries with greater investment in digital technologies show neither differential productivity deceleration nor any evidence of faster quality improvements than those that are less digital.</p>
<p class="tx" id="ji_1479" lang="en-US">A few economists, such as Tyler Cowen and Robert Gordon, believe that this disappointing productivity performance reflects dwindling opportunities for revolutionary breakthroughs. In contrast to techno-optimists, they claim, the great innovations are behind us, and improvements from now on will be incremental, leading only to slow productivity growth.</p>
<p class="tx" id="ji_1480" lang="en-US">There is no consensus among economists about what exactly is going on, but there is little support for the notion that the world is running out of ideas. In fact, as we saw in <a href="009_Chapter_002.xhtml">Chapter 1</a>, there have been tremendous advances in the tools of scientific and technical inquiry and in communication and information acquisition. Rather than being afflicted by a shortage of ideas, quite a bit of evidence suggests that the US and Western economies are <a id="page-293"></a>squandering the available opportunities and scientific know-how. There is a lot of research and innovation. Yet these economies are not getting the expected returns on these activities.</p>
<p class="tx" id="ji_1481" lang="en-US">The simple fact is that the US research and innovation portfolio has become highly imbalanced. Although more resources keep pouring into computers and electronics, almost all other manufacturing sectors are lagging. Recent research shows that new innovations appear to benefit more-productive larger firms, whereas the second- and third-tier firms are falling behind across the industrialized world, most likely because their investments in digital technologies are not paying off.</p>
<p class="tx" id="ji_1482" lang="en-US">More fundamentally, productivity gains from automation may always be somewhat limited, especially compared to the introduction of new products and tasks that transform the production process, such as those in the early Ford factories. Automation is about substituting cheaper machines or algorithms for human labor, and reducing production costs by 10 or even 20 percent in a few tasks will have relatively small consequences for TFP or the efficiency of the production process. In contrast, introducing new technologies, such as electrification, novel designs, or new production tasks, has been at the root of transformative TFP gains throughout much of the twentieth century.</p>
<p class="tx" id="ji_1483" lang="en-US">As innovation has turned its back on boosting worker marginal productivity and creating new tasks for humans over the last forty years, it has also left many “low-hanging fruits.” One place we can get a sense of these forgone productivity opportunities is in the automobile industry. Although the introduction of robots and specialized software has increased output per worker in the industry, there is evidence that investing more in humans would have boosted productivity by more. This is what Japanese car companies, such as Toyota, discovered starting in the 1980s. When they automated more and more tasks, they saw that productivity was not increasing by much because, without the workers in the loop, they were losing flexibility and the ability to adapt to changes in demand and production conditions. In response, the company took a step back and reinstated workers’ central role in crucial production tasks.</p>
<p class="tx" id="ji_1484" lang="en-US"><a id="page-294"></a>Toyota has demonstrated the same possibilities in the United States, too. GM’s Fremont, California, plant suffered from low productivity, unreliable quality, and labor conflict, and it shut down in 1982. In 1983, Toyota and GM launched a joint venture to produce cars for both companies and reopened the Fremont facility, retaining its previous union leadership and workforce. But Toyota applied its own management principles, including the approach of combining advanced machinery with worker training, flexibility, and initiative. Soon Fremont reached productivity and quality levels comparable to those of Toyota’s Japanese plants, much higher than those of US automakers.</p>
<p class="tx" id="ji_1485" lang="en-US">The Tesla electric car company, led by Elon Musk, learned the same lessons more recently. Driven by Musk’s digital utopia, Tesla originally planned to automate almost every part of car production. It did not work. As costs multiplied and delays prevented Tesla from meeting demand, Musk himself admitted, “Yes, excessive automation at Tesla was a mistake. To be precise, my mistake. Humans are underrated.”</p>
<p class="tx" id="ji_1486" lang="en-US">This should not have been a big surprise. Karel Čapek, who christened robots, also recognized their limitations and inability to do the finer things that humans do: “Only years of practice will teach you the mysteries and bold certainty of a real gardener, who treads at random, and yet tramples on nothing.”</p>
<p class="tx" id="ji_1487" lang="en-US">Unexploited low-hanging fruit is even more consequential in the realm of innovation than in the way factories are organized. In the quest for greater automation, managers have ignored technological investments that could boost worker productivity by providing better information and platforms for collaboration and creating new tasks, as we discuss in <a href="017_Chapter_010.xhtml">Chapter 9</a>. With a more balanced portfolio of innovations, rather than the excessive automation focus fueled by the digital utopia, the economy could have achieved faster productivity growth.</p>
<p class="h1" id="ji_1488" lang="en-US">Toward Dystopia</p>
<p class="cotx" id="ji_1489" lang="en-US">The most important driver of the increase in inequality and the loss of ground for most American workers is the new social bias <a id="page-295"></a>of technology. We have seen throughout that we should not bank on technology inexorably benefiting everybody. The productivity bandwagon works only under specific circumstances. It does not operate when there is insufficient competition between employers, little or no worker power, and ceaseless automation.</p>
<p class="tx" id="ji_1490" lang="en-US">In the decades that followed World War II, automation was rapid but went together with equally innovative technologies that increased worker marginal productivity and the demand for labor. It was the combination of these two forces, as well as an environment that encouraged competition between corporations and collective bargaining, that made the productivity bandwagon effective.</p>
<p class="tx" id="ji_1491" lang="en-US">Things look very different from 1980 onward. During this era, we see faster automation but only a few technologies counterbalancing the antilabor bias of automation. Wage growth also slowed down as the labor movement became increasingly impaired. In fact, lack of resistance from the labor movement was likely an important cause of the greater emphasis on automation. Many managers, even during periods of relatively shared prosperity, have a bias toward automation, for this enables them to reduce labor costs and diminish the bargaining power of workers. Once countervailing powers from the labor movement and government regulation weakened, rent sharing subsided, and a natural bias toward automation set in. Now the productivity bandwagon had far fewer people on board.</p>
<p class="tx" id="ji_1492" lang="en-US">Worse, without countervailing powers, digital technologies became engulfed in a new digital utopia, elevating the use of software and machinery to empower companies and sideline labor. Digital solutions imposed from above by technology leaders came to be regarded almost by definition to be in the public interest. Yet what most workers got was much more dystopian: they lost their jobs and their livelihoods.</p>
<p class="tx" id="ji_1493" lang="en-US">There were other ways of developing and using digital technologies. Early hackers, guided by a different vision, pushed the technology frontier toward greater decentralization and out of the hands of large corporations. Several notable successes were based on this alternative approach, even if it remained mostly <a id="page-296"></a>marginal to the main developments of the tech industry, as we will soon see.</p>
<p class="tx" id="ji_1494" lang="en-US">Hence, the bias of technology was very much a choice—and a socially constructed one. Then things started getting much worse, economically, politically, and socially, as tech visionaries found a new tool to remake society: artificial intelligence.</p>
</section>
</div>



  </div>

  
  <div class="calibreToc">
    <h2><a href="../../../Power and Progress Our Thousand-Year Struggle Over Technology and Prosperity (Daron Acemoglu Simon Johnson) (Z-Library).html">Table of contents
</a></h2>
    <div>
  <ul>
    <li>
      <a href="003_Title.xhtml">Title Page</a>
    </li>
    <li>
      <a href="004_Copyright.xhtml">Copyright</a>
    </li>
    <li>
      <a href="005_Dedication.xhtml">Dedication</a>
    </li>
    <li>
      <a href="008_Chapter_001.xhtml">Prologue: What Is Progress?</a>
    </li>
    <li>
      <a href="009_Chapter_002.xhtml">1 Control over Technology</a>
    </li>
    <li>
      <a href="010_Chapter_003.xhtml">2 Canal Vision</a>
    </li>
    <li>
      <a href="011_Chapter_004.xhtml">3 Power to Persuade</a>
    </li>
    <li>
      <a href="012_Chapter_005.xhtml">4 Cultivating Misery</a>
    </li>
    <li>
      <a href="013_Chapter_006.xhtml">5 A Middling Sort of Revolution</a>
    </li>
    <li>
      <a href="014_Chapter_007.xhtml">6 Casualties of Progress</a>
    </li>
    <li>
      <a href="015_Chapter_008.xhtml">7 The Contested Path</a>
    </li>
    <li>
      <a href="016_Chapter_009.xhtml">8 Digital Damage</a>
    </li>
    <li>
      <a href="017_Chapter_010.xhtml">9 Artificial Struggle</a>
    </li>
    <li>
      <a href="018_Chapter_011.xhtml">10 Democracy Breaks</a>
    </li>
    <li>
      <a href="019_Chapter_012.xhtml">11 Redirecting Technology</a>
    </li>
    <li>
      <a href="020_Bm.xhtml">Photos</a>
    </li>
    <li>
      <a href="054_Bm.xhtml">Bibliographic Essay</a>
    </li>
    <li>
      <a href="055_Bm.xhtml">References</a>
    </li>
    <li>
      <a href="056_Bm.xhtml">Acknowledgments</a>
    </li>
    <li>
      <a href="discover-page.xhtml">Discover More</a>
    </li>
    <li>
      <a href="057_Bm.xhtml">Image Credits</a>
    </li>
    <li>
      <a href="058_Bm.xhtml">About the Authors</a>
    </li>
    <li>
      <a href="002_ad-card.xhtml">Also by Daron Acemoglu</a>
    </li>
    <li>
      <a href="002_ad-card.xhtml#toc_2b">Also by Simon Johnson</a>
    </li>
    <li>
      <a href="001_Fm.xhtml">Praise for "Power and Progress"</a>
    </li>
  </ul>
</div>


  </div>
  

  <div class="calibreEbNav">
    
      <a href="015_Chapter_008.xhtml" class="calibreAPrev">previous page
</a>
    

    <a href="../../../Power and Progress Our Thousand-Year Struggle Over Technology and Prosperity (Daron Acemoglu Simon Johnson) (Z-Library).html" class="calibreAHome">start
</a>

    
      <a href="017_Chapter_010.xhtml" class="calibreANext">next page
</a>
    
  </div>

</div>

</body>
</html>
